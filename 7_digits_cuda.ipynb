{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU computation & batching for speed\n",
    "The objective of this notebook is to teach you to make training faster from a computational perspective.\n",
    "\n",
    "1) We will use a GPU to accelerate our computation.\n",
    "\n",
    "2) We will batch our computation in the sense that the network will process multiple samples **at once**.\n",
    "\n",
    "Your task: modify the test code to also run in batches on the GPU.\n",
    "\n",
    "This will allow us to try larger networks :) - play with it.  See what accuracy you can get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ready\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'cutorch'\n",
    "require 'nn'\n",
    "require 'cunn'\n",
    "require 'optim'\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutorch.setDevice(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.2408  1.0470\n",
       " 0.7939  0.5975\n",
       " 0.3365 -0.6204\n",
       "-2.7366  1.8571\n",
       "-0.3617  2.1894\n",
       " 2.5983 -1.1267\n",
       " 0.1394  0.2652\n",
       "-0.5232 -1.6361\n",
       " 1.7156  0.1754\n",
       "-0.7697 -0.2960\n",
       "[torch.DoubleTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.2408  1.0470\n",
       " 0.7939  0.5975\n",
       " 0.3365 -0.6204\n",
       "-2.7366  1.8571\n",
       "-0.3617  2.1894\n",
       " 2.5983 -1.1267\n",
       " 0.1394  0.2652\n",
       "-0.5232 -1.6361\n",
       " 1.7156  0.1754\n",
       "-0.7697 -0.2960\n",
       "[torch.CudaTensor of size 10x2]\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc = x:cuda()\n",
    "print(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "bad argument #2 to '?' (number expected, got userdata)\nstack traceback:\n\t[C]: at 0x7f577501af90\n\t[C]: in function '__add'\n\t[string \"local f = function() return -- you cannot ope...\"]:3: in function 'f'\n\t[string \"local f = function() return -- you cannot ope...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t/usr/local/share/torch/share/lua/5.1/itorch/main.lua:179: in function </usr/local/share/torch/share/lua/5.1/itorch/main.lua:143>\n\t/usr/local/share/torch/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/usr/local/share/torch/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/usr/local/share/torch/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/usr/local/share/torch/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/usr/local/share/torch/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/home_lustre/dd-15-28-13/.local/share/j...\"]:1: in main chunk",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "bad argument #2 to '?' (number expected, got userdata)\nstack traceback:\n\t[C]: at 0x7f577501af90\n\t[C]: in function '__add'\n\t[string \"local f = function() return -- you cannot ope...\"]:3: in function 'f'\n\t[string \"local f = function() return -- you cannot ope...\"]:3: in main chunk\n\t[C]: in function 'xpcall'\n\t/usr/local/share/torch/share/lua/5.1/itorch/main.lua:179: in function </usr/local/share/torch/share/lua/5.1/itorch/main.lua:143>\n\t/usr/local/share/torch/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/usr/local/share/torch/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/usr/local/share/torch/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/usr/local/share/torch/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/usr/local/share/torch/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t[string \"arg={'/home_lustre/dd-15-28-13/.local/share/j...\"]:1: in main chunk"
     ]
    }
   ],
   "source": [
    "-- you cannot operate on vectors living in different memory\n",
    "-- the errors given are counterintuitive\n",
    "print(x+xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.8116 -1.9104\n",
       " 0.2679  2.9092\n",
       "[torch.CudaTensor of size 2x2]\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- if we create another variable on the GPU, we can happily operate on those\n",
    "yc = torch.randn(10,2):cuda()\n",
    "print(torch.mm(yc:t(),xc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> loading dataset\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- this should be familiar - we load up the data\n",
    "\n",
    "-- snippet shamelessly ripped from https://github.com/torch/tutorials/blob/master/A_datasets/mnist.lua \n",
    "-- load the training data (downloads when first used)\n",
    "tar = 'http://torch7.s3-website-us-east-1.amazonaws.com/data/mnist.t7.tgz'\n",
    "\n",
    "if not paths.dirp('mnist.t7') then\n",
    "   print('==> downloading dataset')\n",
    "   os.execute('wget ' .. tar)\n",
    "   os.execute('tar xvf ' .. paths.basename(tar))\n",
    "end\n",
    "\n",
    "train_file = 'mnist.t7/train_32x32.t7'\n",
    "test_file = 'mnist.t7/test_32x32.t7'\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print('==> loading dataset')\n",
    "\n",
    "-- We load the dataset from disk, it's straightforward\n",
    "\n",
    "train_data = torch.load(train_file,'ascii')\n",
    "test_data = torch.load(test_file,'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- let's preprocess the data a bit, so they are between 0 and 1\n",
    "-- NEW: and move them to the GPU\n",
    "train_data.data = train_data.data:reshape(60000,1024):type('torch.DoubleTensor'):mul(1.0 / 256.0):cuda()\n",
    "train_data.labels = train_data.labels:cuda()\n",
    "test_data.data = test_data.data:reshape(10000,1024):type('torch.DoubleTensor'):mul(1.0 / 256.0):cuda()\n",
    "test_data.labels = test_data.labels:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAA+0lEQVQ4jWNgGImAWUhIqK5jvdSy/9/rISIsCEk5NisbgWAGBgaGJ5MCP188CBFlhMsb7uWHsv4lfWV49v4muulCt//+/fv377Ft3z/isD9gTvbfv2e5GbRn4XIhH+Osv1HogkxI7E//PzKkMKGrQAHc+/664VXAoPzx4YIcRnwqAj/8/VsuiU+F7q6/f6dJ41MhEPvn7278Dvn596cDnMOCLqsXYsrCcO0QLs3qU57+/fv31zYc0hJFd//+/fv3pB92aXGnq3///v17LBB7YAqtvv3379+/hwM4sUqbr3n09+/fv19audFloL4IDGRguL75b88HXK4f3AAAdeZegIC2SaMAAAAASUVORK5CYII=",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- itorch.image will accept arrays living on the GPU\n",
    "itorch.image(train_data.data[1]:reshape(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]\n",
       "  (1): nn.Linear(1024 -> 700)\n",
       "  (2): nn.PReLU\n",
       "  (3): nn.Linear(700 -> 500)\n",
       "  (4): nn.PReLU\n",
       "  (5): nn.Linear(500 -> 300)\n",
       "  (6): nn.PReLU\n",
       "  (7): nn.Linear(300 -> 100)\n",
       "  (8): nn.PReLU\n",
       "  (9): nn.Linear(100 -> 10)\n",
       "}\n",
       "{\n",
       "  gradInput : CudaTensor - empty\n",
       "  modules : \n",
       "    {\n",
       "      1 : \n",
       "        nn.Linear(1024 -> 700)\n",
       "        {\n",
       "          gradBias : CudaTensor - size: 700\n",
       "          weight : CudaTensor - size: 700x1024\n",
       "          bias : CudaTensor - size: 700\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 700x1024\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      2 : \n",
       "        nn.PReLU\n",
       "        {\n",
       "          weight : CudaTensor - size: 1\n",
       "          nOutputPlane : 0\n",
       "          output : CudaTensor - empty\n",
       "          gradInput : CudaTensor - empty\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          gradWeightBuf2 : CudaTensor - empty\n",
       "          gradWeightBuf : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 1\n",
       "        }\n",
       "      3 : \n",
       "        nn.Linear(700 -> 500)\n",
       "        {\n",
       "          gradBias : CudaTensor - size: 500\n",
       "          weight : CudaTensor - size: 500x700\n",
       "          bias : CudaTensor - size: 500\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 500x700\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      4 : \n",
       "        nn.PReLU\n",
       "        {\n",
       "          weight : CudaTensor - size: 1\n",
       "          nOutputPlane : 0\n",
       "          output : CudaTensor - empty\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeightBuf2 : CudaTensor - empty\n",
       "          gradWeightBuf : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 1\n",
       "        }\n",
       "      5 : \n",
       "        nn.Linear(500 -> 300)\n",
       "        {\n",
       "          gradBias : CudaTensor - size: 300\n",
       "          weight : CudaTensor - size: 300x500\n",
       "          bias : CudaTensor - size: 300\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 300x500\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      6 : \n",
       "        nn.PReLU\n",
       "        {\n",
       "          weight : CudaTensor - size: 1\n",
       "          nOutputPlane : 0\n",
       "          output : CudaTensor - empty\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeightBuf2 : CudaTensor - empty\n",
       "          gradWeightBuf : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 1\n",
       "        }\n",
       "      7 : \n",
       "        nn.Linear(300 -> 100)\n",
       "        {\n",
       "          gradBias : CudaTensor - size: 100\n",
       "          weight : CudaTensor - size: 100x300\n",
       "          bias : CudaTensor - size: 100\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 100x300\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "      8 : \n",
       "        nn.PReLU\n",
       "        {\n",
       "          weight : CudaTensor - size: 1\n",
       "          nOutputPlane : 0\n",
       "          output : CudaTensor - empty\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeightBuf2 : CudaTensor - empty\n",
       "   "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "       gradWeightBuf : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 1\n",
       "        }\n",
       "      9 : \n",
       "        nn.Linear(100 -> 10)\n",
       "        {\n",
       "          gradBias : CudaTensor - size: 10\n",
       "          weight : CudaTensor - size: 10x100\n",
       "          bias : CudaTensor - size: 10\n",
       "          gradInput : CudaTensor - empty\n",
       "          gradWeight : CudaTensor - size: 10x100\n",
       "          output : CudaTensor - empty\n",
       "        }\n",
       "    }\n",
       "  output : CudaTensor - empty\n",
       "}\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "*** Total number of parameters = 1249414 ***\t\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net:add(nn.Linear(1024,700))\n",
    "net:add(nn.PReLU())\n",
    "net:add(nn.Linear(700,500))\n",
    "net:add(nn.PReLU())\n",
    "net:add(nn.Linear(500,300))\n",
    "net:add(nn.PReLU())\n",
    "net:add(nn.Linear(300,100))\n",
    "net:add(nn.PReLU())\n",
    "net:add(nn.Linear(100, 10))\n",
    "\n",
    "-- move entire network to the GPU\n",
    "net = net:cuda()\n",
    "\n",
    "-- loss is cross-entropy (== logsoftmax + classnllcriterion)\n",
    "loss = nn.CrossEntropyCriterion():cuda()\n",
    "print(net)\n",
    "\n",
    "parameters, gradParameters = net:getParameters()\n",
    "print('*** Total number of parameters = ' .. parameters:nElement() .. ' ***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = torch.load('mojeNN.dat'):cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- random initialization according to Xavier\n",
    "local tmp = math.sqrt(1. / net:get(1).bias:size(1))\n",
    "net:get(1).weight:uniform(-tmp, tmp)\n",
    "net:get(1).bias:zero()\n",
    "local tmp = math.sqrt(1. / net:get(3).bias:size(1))\n",
    "net:get(3).weight:uniform(-tmp, tmp)\n",
    "net:get(3).bias:zero()\n",
    "local tmp = math.sqrt(1. / net:get(5).bias:size(1))\n",
    "net:get(5).weight:uniform(-tmp, tmp)\n",
    "net:get(5).bias:zero()\n",
    "local tmp = math.sqrt(1. / net:get(7).bias:size(1))\n",
    "net:get(7).weight:uniform(-tmp, tmp)\n",
    "net:get(7).bias:zero()\n",
    "local tmp = math.sqrt(1. / net:get(9).bias:size(1))\n",
    "net:get(9).weight:uniform(-tmp, tmp)\n",
    "net:get(9).bias:zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- reset the state of the optimizer\n",
    "opt_state = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "******************* EPOCH 1 ************************\t\n",
       "TRAINING [error = 0.00024940184084699]\t\n",
       "ConfusionMatrix:\n",
       "[[    5923       0       0       0       0       0       0       0       0       0]   100.000% \t[class: 0]\n",
       " [       0    6742       0       0       0       0       0       0       0       0]   100.000% \t[class: 1]\n",
       " [       0       0    5958       0       0       0       0       0       0       0]   100.000% \t[class: 2]\n",
       " [       0       0       0    6131       0       0       0       0       0       0]   100.000% \t[class: 3]\n",
       " [       0       0       0       0    5842       0       0       0       0       0]   100.000% \t[class: 4]\n",
       " [       0       0       0       0       0    5421       0       0       0       0]   100.000% \t[class: 5]\n",
       " [       0       0       0       0       0       0    5918       0       0       0]   100.000% \t[class: 6]\n",
       " [       0       0       0       0       0       0       0    6265       0       0]   100.000% \t[class: 7]\n",
       " [       0       0       0       0       0       0       0       0    5851       0]   100.000% \t[class: 8]\n",
       " [       0       0       0       0       0       0       0       0       1    5948]]  99.983% \t[class: 9]\n",
       " + average row correct: 99.998319149017% \n",
       " + average rowUcol correct (VOC measure): 99.996610283852% \n",
       " + global correct: 99.998333333333%\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TESTING [error = 2006.8659954071] misses = 219\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     965       1       1       2       1       2       4       0       2       2]   98.469% \t[class: 0]\n",
       " [       0    1126       1       2       1       0       1       0       4       0]   99.207% \t[class: 1]\n",
       " [       5       1    1004       6       2       0       3       5       6       0]   97.287% \t[class: 2]\n",
       " [       0       0       3     985       0       7       0       6       3       6]   97.525% \t[class: 3]\n",
       " [       1       0       2       0     961       0       4       3       0      11]   97.862% \t[class: 4]\n",
       " [       3       0       0       7       0     874       4       1       2       1]   97.982% \t[class: 5]\n",
       " [       5       3       2       0       5       8     932       0       3       0]   97.286% \t[class: 6]\n",
       " [       2       7       7       1       1       0       0    1004       3       3]   97.665% \t[class: 7]\n",
       " [       4       0       4       7       1       2       0       2     949       5]   97.433% \t[class: 8]\n",
       " [       2       3       0       3       9       5       1       4       1     981]]  97.225% \t[class: 9]\n",
       " + average row correct: 97.794119119644% \n",
       " + average rowUcol correct (VOC measure): 95.686468482018% \n",
       " + global correct: 97.81%\t\n",
       "Epoch took 8.545567035675 seconds.\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "******************* EPOCH 2 ************************\t\n",
       "TRAINING [error = 0.00017538496467751]\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    5923       0       0       0       0       0       0       0       0       0]   100.000% \t[class: 0]\n",
       " [       0    6742       0       0       0       0       0       0       0       0]   100.000% \t[class: 1]\n",
       " [       0       0    5958       0       0       0       0       0       0       0]   100.000% \t[class: 2]\n",
       " [       0       0       0    6131       0       0       0       0       0       0]   100.000% \t[class: 3]\n",
       " [       0       0       0       0    5842       0       0       0       0       0]   100.000% \t[class: 4]\n",
       " [       0       0       0       0       0    5421       0       0       0       0]   100.000% \t[class: 5]\n",
       " [       0       0       0       0       0       0    5918       0       0       0]   100.000% \t[class: 6]\n",
       " [       0       0       0       0       0       0       0    6265       0       0]   100.000% \t[class: 7]\n",
       " [       0       0       0       0       0       0       0       0    5851       0]   100.000% \t[class: 8]\n",
       " [       0       0       0       0       0       0       0       0       1    5948]]  99.983% \t[class: 9]\n",
       " + average row correct: 99.998319149017% \n",
       " + average rowUcol correct (VOC measure): 99.996610283852% \n",
       " + global correct: 99.998333333333%\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TESTING [error = 2004.1554298401] misses = 219\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     965       1       1       2       1       2       4       0       2       2]   98.469% \t[class: 0]\n",
       " [       0    1126       1       2       1       0       1       0       4       0]   99.207% \t[class: 1]\n",
       " [       4       1    1005       6       2       0       3       5       6       0]   97.384% \t[class: 2]\n",
       " [       0       0       3     986       0       6       0       6       3       6]   97.624% \t[class: 3]\n",
       " [       1       0       2       0     961       0       4       3       0      11]   97.862% \t[class: 4]\n",
       " [       3       0       0       7       0     873       4       1       3       1]   97.870% \t[class: 5]\n",
       " [       5       3       2       0       5       8     932       0       3       0]   97.286% \t[class: 6]\n",
       " [       2       7       8       1       1       0       0    1003       3       3]   97.568% \t[class: 7]\n",
       " [       4       0       4       7       1       1       1       2     949       5]   97.433% \t[class: 8]\n",
       " [       2       3       0       3       9       5       1       4       1     981]]  97.225% \t[class: 9]\n",
       " + average row correct: 97.792772054672% \n",
       " + average rowUcol correct (VOC measure): 95.687248706818% \n",
       " + global correct: 97.81%\t\n",
       "Epoch took 8.6960849761963 seconds.\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "******************* EPOCH 3 ************************\t\n",
       "TRAINING [error = 0.00015932458336465]\t\n",
       "ConfusionMatrix:\n",
       "[[    5923       0       0       0       0       0       0       0       0       0]   100.000% \t[class: 0]\n",
       " [       0    6742       0       0       0       0       0       0       0       0]   100.000% \t[class: 1]\n",
       " [       0       0    5958       0       0       0       0       0       0       0]   100.000% \t[class: 2]\n",
       " [       0       0       0    6131       0       0       0       0       0       0]   100.000% \t[class: 3]\n",
       " [       0       0       0       0    5842       0       0       0       0       0]   100.000% \t[class: 4]\n",
       " [       0       0       0       0       0    5421       0       0       0       0]   100.000% \t[class: 5]\n",
       " [       0       0       0       0       0       0    5918       0       0       0]   100.000% \t[class: 6]\n",
       " [       0       0       0       0       0       0       0    6265       0       0]   100.000% \t[class: 7]\n",
       " [       0       0       0       0       0       0       0       0    5851       0]   100.000% \t[class: 8]\n",
       " [       0       0       0       0       0       0       0       0       1    5948]]  99.983% \t[class: 9]\n",
       " + average row correct: 99.998319149017% \n",
       " + average rowUcol correct (VOC measure): 99.996610283852% \n",
       " + global correct: 99.998333333333%\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TESTING [error = 2004.5409355164] misses = 216\t\n",
       "ConfusionMatrix:\n",
       "[[     965       1       1       2       1       2       4       0       2       2]   98.469% \t[class: 0]\n",
       " [       0    1126       1       2       1       0       1       0       4       0]   99.207% \t[class: 1]\n",
       " [       3       1    1006       6       2       0       3       5       6       0]   97.481% \t[class: 2]\n",
       " [       0       0       3     988       0       5       0       6       3       5]   97.822% \t[class: 3]\n",
       " [       1       0       2       0     961       0       4       3       0      11]   97.862% \t[class: 4]\n",
       " [       3       0       0       7       0     873       4       1       3       1]   97.870% \t[class: 5]\n",
       " [       5       3       2       0       5       8     932       0       3       0]   97.286% \t[class: 6]\n",
       " [       2       7       8       1       1       0       0    1003       3       3]   97.568% \t[class: 7]\n",
       " [       4       0       4       7       1       1       1       2     949       5]   97.433% \t[class: 8]\n",
       " [       2       3       0       3       9       5       1       4       1     981]]  97.225% \t[class: 9]\n",
       " + average row correct: 97.822264432907% \n",
       " + average rowUcol correct (VOC measure): 95.745245218277% \n",
       " + global correct: 97.84%\t\n",
       "Epoch took 8.4866161346436 seconds.\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "******************* EPOCH 4 ************************\t\n",
       "TRAINING [error = 0.00015261919179466]\t\n",
       "ConfusionMatrix:\n",
       "[[    5923       0       0       0       0       0       0       0       0       0]   100.000% \t[class: 0]\n",
       " [       0    6742       0       0       0       0       0       0       0       0]   100.000% \t[class: 1]\n",
       " [       0       0    5958       0       0       0       0       0       0       0]   100.000% \t[class: 2]\n",
       " [       0       0       0    6131       0       0       0       0       0       0]   100.000% \t[class: 3]\n",
       " [       0       0       0       0    5842       0       0       0       0       0]   100.000% \t[class: 4]\n",
       " [       0       0       0       0       0    5421       0       0       0       0]   100.000% \t[class: 5]\n",
       " [       0       0       0       0       0       0    5918       0       0       0]   100.000% \t[class: 6]\n",
       " [       0       0       0       0       0       0       0    6265       0       0]   100.000% \t[class: 7]\n",
       " [       0       0       0       0       0       0       0       0    5851       0]   100.000% \t[class: 8]\n",
       " [       0       0       0       0       0       0       0       0       1    5948]]  99.983% \t[class: 9]\n",
       " + average row correct: 99.998319149017% \n",
       " + average rowUcol correct (VOC measure): 99.996610283852% \n",
       " + global correct: 99.998333333333%\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TESTING [error = 2006.1976108551] misses = 215\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     965       1       1       2       1       2       4       0       2       2]   98.469% \t[class: 0]\n",
       " [       0    1126       1       2       1       0       1       0       4       0]   99.207% \t[class: 1]\n",
       " [       3       1    1006       6       2       0       3       5       6       0]   97.481% \t[class: 2]\n",
       " [       0       0       3     989       0       4       0       6       3       5]   97.921% \t[class: 3]\n",
       " [       1       0       2       0     962       0       4       3       0      10]   97.963% \t[class: 4]\n",
       " [       3       0       0       7       0     873       4       1       3       1]   97.870% \t[class: 5]\n",
       " [       5       3       2       0       5       8     932       0       3       0]   97.286% \t[class: 6]\n",
       " [       2       7       8       1       1       0       0    1003       3       3]   97.568% \t[class: 7]\n",
       " [       4       0       5       7       1       1       1       2     948       5]   97.331% \t[class: 8]\n",
       " [       2       3       0       3       9       5       1       4       1     981]]  97.225% \t[class: 9]\n",
       " + average row correct: 97.832081913948% \n",
       " + average rowUcol correct (VOC measure): 95.765418410301% \n",
       " + global correct: 97.85%\t\n",
       "Epoch took 8.4643340110779 seconds.\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "******************* EPOCH 5 ************************\t\n",
       "TRAINING [error = 0.00014900745009072]\t\n",
       "ConfusionMatrix:\n",
       "[[    5923       0       0       0       0       0       0       0       0       0]   100.000% \t[class: 0]\n",
       " [       0    6742       0       0       0       0       0       0       0       0]   100.000% \t[class: 1]\n",
       " [       0       0    5958       0       0       0       0       0       0       0]   100.000% \t[class: 2]\n",
       " [       0       0       0    6131       0       0       0       0       0       0]   100.000% \t[class: 3]\n",
       " [       0       0       0       0    5842       0       0       0       0       0]   100.000% \t[class: 4]\n",
       " [       0       0       0       0       0    5421       0       0       0       0]   100.000% \t[class: 5]\n",
       " [       0       0       0       0       0       0    5918       0       0       0]   100.000% \t[class: 6]\n",
       " [       0       0       0       0       0       0       0    6265       0       0]   100.000% \t[class: 7]\n",
       " [       0       0       0       0       0       0       0       0    5851       0]   100.000% \t[class: 8]\n",
       " [       0       0       0       0       0       0       0       0       1    5948]]  99.983% \t[class: 9]\n",
       " + average row correct: 99.998319149017% \n",
       " + average rowUcol correct (VOC measure): 99.996610283852% \n",
       " + global correct: 99.998333333333%\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TESTING [error = 2008.1472010612] misses = 217\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[     965       1       1       2       1       2       4       0       2       2]   98.469% \t[class: 0]\n",
       " [       0    1126       1       2       1       0       1       0       4       0]   99.207% \t[class: 1]\n",
       " [       3       1    1006       6       2       0       3       5       6       0]   97.481% \t[class: 2]\n",
       " [       0       0       3     989       0       4       0       6       3       5]   97.921% \t[class: 3]\n",
       " [       1       0       2       0     962       0       4       3       0      10]   97.963% \t[class: 4]\n",
       " [       3       0       0       7       0     872       4       1       4       1]   97.758% \t[class: 5]\n",
       " [       5       3       2       0       5       8     932       0       3       0]   97.286% \t[class: 6]\n",
       " [       2       7       8       1       1       0       0    1003       3       3]   97.568% \t[class: 7]\n",
       " [       4       0       5       7       1       1       1       2     948       5]   97.331% \t[class: 8]\n",
       " [       2       3       0       3       9       5       1       5       1     980]]  97.126% \t[class: 9]\n",
       " + average row correct: 97.810960412025% \n",
       " + average rowUcol correct (VOC measure): 95.7261967659% \n",
       " + global correct: 97.83%\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch took 8.3737559318542 seconds.\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_optimizer = optim.sgd\n",
    "opt_config = {\n",
    "    learningRate = 0.05,\n",
    "    momentum = 0.6,\n",
    "}\n",
    "\n",
    "execute_optimizer = optim.adadelta\n",
    "opt_config = {\n",
    "   rho = 0.99,\n",
    "   eps = 1e-8\n",
    "}\n",
    "\n",
    "-- execute_optimizer = optim.rmsprop\n",
    "-- opt_config = {\n",
    "--    learningRate = 0.01,\n",
    "-- }\n",
    "\n",
    "nepochs = 5\n",
    "ntrain = 60000\n",
    "ntest = 10000\n",
    "batch_size = 60000\n",
    "etest = 1\n",
    "diagnostic_level = 1\n",
    "\n",
    "-- train the network\n",
    "for e=1,nepochs do\n",
    "    \n",
    "    local timer = torch.Timer() \n",
    "    local confmat = optim.ConfusionMatrix(10, {'0','1','2','3','4','5','6','7','8','9'})\n",
    "    local train_err = 0\n",
    "    local inputs = torch.Tensor(batch_size,32*32):cuda()\n",
    "    local targets = torch.Tensor(batch_size):cuda()\n",
    "    \n",
    "    for b=1,ntrain/batch_size do\n",
    "        \n",
    "        function batch_eval(x)\n",
    "            \n",
    "            local err = 0\n",
    "            \n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "\n",
    "            -- fill up the batch vector\n",
    "            for i=1,batch_size do\n",
    "                local ndx = (b-1) * batch_size + i\n",
    "                inputs[i]:copy(train_data.data[ndx])\n",
    "                targets[i] = train_data.labels[ndx]\n",
    "            end\n",
    "            \n",
    "            gradParameters:zero()\n",
    "            \n",
    "            local ys = net:forward(inputs)\n",
    "            local batch_err = loss:forward(ys, targets)\n",
    "            local dt_dy = loss:backward(ys, targets)\n",
    "            net:backward(inputs, dt_dy)\n",
    "            \n",
    "            -- add all results into the confusion matrix\n",
    "            for i=1,batch_size do\n",
    "                confmat:add(ys[i],targets[i])\n",
    "            end\n",
    "        \n",
    "            train_err = train_err + batch_err\n",
    "            return batch_err, gradParameters\n",
    "        end\n",
    "        \n",
    "        execute_optimizer(batch_eval, parameters, opt_config, opt_state)\n",
    "    end\n",
    "    \n",
    "    print('******************* EPOCH ' .. e .. ' ************************')\n",
    "\n",
    "    print('TRAINING [error = ' .. train_err .. ']')\n",
    "    if diagnostic_level > 0 then\n",
    "        print(confmat:__tostring__())\n",
    "    end\n",
    "    \n",
    "    -- compute testing error every etest epochs\n",
    "    if e % etest == 0 then\n",
    "        local terr = 0\n",
    "        local misses = 0\n",
    "        confmat:zero()\n",
    "        for i=1,ntest do\n",
    "            local x = test_data.data[i]\n",
    "            local t = test_data.labels[i]\n",
    "            local y = net:forward(x)\n",
    "            confmat:add(y, t)\n",
    "            local _, digit = torch.max(y,1)\n",
    "            digit = digit[1]\n",
    "            if digit ~= t then\n",
    "                misses = misses + 1\n",
    "            end\n",
    "            terr = terr + loss:forward(y, t)\n",
    "        end\n",
    "        print('TESTING [error = ' .. terr .. '] misses = ' .. misses)\n",
    "        if diagnostic_level > 0 then\n",
    "            print(confmat:__tostring__())\n",
    "        end\n",
    "    end\n",
    "        \n",
    "    print('Epoch took ' .. timer:time().real .. ' seconds.')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save('mojeNN.dat', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
