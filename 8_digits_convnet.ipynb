{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional networks\n",
    "The objective of this worksheet is to introduce you to a specific type of layer: the convolutional layer.\n",
    "Neural networks that contain such layers are typically called 'Convolutional networks'.\n",
    "\n",
    "- 'convnets' for short, are networks with their initial layers based on the operation of convolution\n",
    "- convolutional layers have several effects\n",
    " - they improve the statistical efficiency through parameter sharing a.k.a. tied weights (a regularization effect)\n",
    " - they can be seen as filters of the input that pick out a specific feature over the entire input\n",
    " - main uses: image and signal processing, recently also for text processing\n",
    "- conv layers are often coupled together with aggregating layers to reduce the number of neurons in subsequent layers -> max pooling\n",
    "\n",
    "\n",
    "1. Time this code (per-epoch) on your computational device, on the zseason computer, it takes 75s/epoch.  We don't like that.\n",
    "2. Can you convert this to GPU-based code? How fast can you make it run?\n",
    "3. What is the lowest test error you can achieve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ready\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'torch'\n",
    "require 'nn'\n",
    "require 'utils'\n",
    "require 'optim'\n",
    "require 'cunn'\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> loading dataset\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- snippet shamelessly ripped from https://github.com/torch/tutorials/blob/master/A_datasets/mnist.lua \n",
    "-- load the training data (downloads when first used)\n",
    "tar = 'http://torch7.s3-website-us-east-1.amazonaws.com/data/mnist.t7.tgz'\n",
    "\n",
    "if not paths.dirp('mnist.t7') then\n",
    "   print('==> downloading dataset')\n",
    "   os.execute('wget ' .. tar)\n",
    "   os.execute('tar xvf ' .. paths.basename(tar))\n",
    "end\n",
    "\n",
    "train_file = 'mnist.t7/train_32x32.t7'\n",
    "test_file = 'mnist.t7/test_32x32.t7'\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "print('==> loading dataset')\n",
    "\n",
    "-- We load the dataset from disk, it's straightforward\n",
    "\n",
    "train_data = torch.load(train_file,'ascii')\n",
    "test_data = torch.load(test_file,'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- let's preprocess the data a bit, so they are between 0 and 1\n",
    "train_data.data = train_data.data:type('torch.DoubleTensor'):mul(1.0 / 256.0):cuda()\n",
    "test_data.data = test_data.data:type('torch.DoubleTensor'):mul(1.0 / 256.0):cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = test_data.data[{519}]:clone()\n",
    "itorch.image(img)\n",
    "itorch.image(utils.enlarge(img,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?nn.SpatialConvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2 = nn.SpatialConvolution(1, 1, 2, 2)\n",
    "print(conv2)\n",
    "conv2.weight:zero()\n",
    "conv2.weight[{1,1,1,1}] = -1\n",
    "conv2.weight[{1,1,2,2}] = 1\n",
    "conv2.bias[1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- let's print out only the last two dimensions\n",
    "print(conv2.weight[{1,1}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- what does this filter do?\n",
    "itorch.image(utils.enlarge(conv2:forward(img),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Pooling\n",
    "- reducing the amount of processed data\n",
    "- enforcing translational invariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?nn.SpatialMaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mp = nn.SpatialMaxPooling(2, 2, 2, 2)\n",
    "seq = nn.Sequential()\n",
    "seq:add(conv2)\n",
    "seq:add(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itorch.image(utils.enlarge(seq:forward(img), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple filters at the same time - input/output planes\n",
    "- planes allow us to keep the networks sequential while being able to apply multiple filters\n",
    "- we **stack** filters on top of each other to generate multiple output images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv2_2 = nn.SpatialConvolution(1, 2, 2, 2)\n",
    "conv2_2.weight:zero()\n",
    "print(conv2_2.weight:size())\n",
    "conv2_2.weight[{1,1,{1,2},1}] = 1\n",
    "conv2_2.weight[{1,1,{1,2},2}] = -1\n",
    "conv2_2.weight[{2,1,1,{1,2}}] = 1\n",
    "conv2_2.weight[{2,1,2,{1,2}}] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2_2 = conv2_2:forward(img)\n",
    "print(img2_2:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- iTorch already knows, how to handle stacks of images\n",
    "itorch.image(utils.enlarge(img2_2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?nn.Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?nn.SpatialMaxPooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional network to process MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn.Sequential {\n",
       "  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> (10) -> (11) -> (12) -> output]\n",
       "  (1): nn.SpatialConvolution(1 -> 8, 5x5)\n",
       "  (2): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (3): nn.ReLU\n",
       "  (4): nn.SpatialConvolution(8 -> 16, 3x3)\n",
       "  (5): nn.SpatialMaxPooling(2,2,2,2)\n",
       "  (6): nn.ReLU\n",
       "  (7): nn.SpatialConvolution(16 -> 32, 3x3)\n",
       "  (8): nn.View\n",
       "  (9): nn.Linear(512 -> 128)\n",
       "  (10): nn.ReLU\n",
       "  (11): nn.Dropout(0.500000)\n",
       "  (12): nn.Linear(128 -> 10)\n",
       "}\n",
       "{\n",
       "  gradInput : DoubleTensor - empty\n",
       "  modules : \n",
       "    {\n",
       "  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "    1 : \n",
       "        nn.SpatialConvolution(1 -> 8, 5x5)\n",
       "        {\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          nOutputPlane : 8\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          gradBias : DoubleTensor - size: 8\n",
       "          padH : 0\n",
       "          weight : DoubleTensor - size: 8x1x5x5\n",
       "          bias : DoubleTensor - size: 8\n",
       "          gradWeight : DoubleTensor - size: 8x1x5x5\n",
       "          padW : 0\n",
       "          nInputPlane : 1\n",
       "          kW : 5\n",
       "          kH : 5\n",
       "        }\n",
       "      2 : \n",
       "        nn.SpatialMaxPooling(2,2,2,2)\n",
       "        {\n",
       "    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      dH : 2\n",
       "          dW : 2\n",
       "          padH : 0\n",
       "          gradInput : DoubleTensor - empty\n",
       "          indices : DoubleTensor - empty\n",
       "          kH : 2\n",
       "          ceil_mode : false\n",
       "          output : DoubleTensor - empty\n",
       "          padW : 0\n",
       "          kW : 2\n",
       "        }\n",
       "      3 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n",
       "          threshold : 0\n",
       "          val : 0\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "        }\n",
       "      4 : \n",
       "        nn.SpatialConvolution(8 -> 16, 3x3)\n",
       "        {\n",
       "          dH : 1\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "          dW : 1\n",
       "          nOutputPlane : 16\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          gradBias : DoubleTensor - size: 16\n",
       "          padH : 0\n",
       "          weight : DoubleTensor - size: 16x8x3x3\n",
       "          bias : DoubleTensor - size: 16\n",
       "          gradWeight : DoubleTensor - size: 16x8x3x3\n",
       "          padW : 0\n",
       "          nInputPlane : 8\n",
       "          kW : 3\n",
       "          kH : 3\n",
       "        }\n",
       "      5 : \n",
       "        nn.SpatialMaxPooling(2,2,2,2)\n",
       "        {\n",
       "          dH : 2\n",
       "          dW : 2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "          padH : 0\n",
       "          gradInput : DoubleTensor - empty\n",
       "          indices : DoubleTensor - empty\n",
       "          kH : 2\n",
       "          ceil_mode : false\n",
       "          output : DoubleTensor - empty\n",
       "          padW : 0\n",
       "          kW : 2\n",
       "        }\n",
       "      6 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n",
       "          threshold : 0\n",
       "          val : 0\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "        }\n",
       "      7 : \n",
       "        nn.SpatialConvolution(16 -> 32, 3x3)\n",
       "        {\n",
       "          dH : 1\n",
       "          dW : 1\n",
       "          "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "nOutputPlane : 32\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "          gradBias : DoubleTensor - size: 32\n",
       "          padH : 0\n",
       "          weight : DoubleTensor - size: 32x16x3x3\n",
       "          bias : DoubleTensor - size: 32\n",
       "          gradWeight : DoubleTensor - size: 32x16x3x3\n",
       "          padW : 0\n",
       "          nInputPlane : 16\n",
       "          kW : 3\n",
       "          kH : 3\n",
       "        }\n",
       "      8 : \n",
       "        nn.View\n",
       "        {\n",
       "          numInputDims : 3\n",
       "          size : LongStorage - size: 1\n",
       "          numElements : 512\n",
       "        }\n",
       "      9 : \n",
       "     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   nn.Linear(512 -> 128)\n",
       "        {\n",
       "          gradBias : DoubleTensor - size: 128\n",
       "          weight : DoubleTensor - size: 128x512\n",
       "          bias : DoubleTensor - size: 128\n",
       "          gradInput : DoubleTensor - empty\n",
       "          gradWeight : DoubleTensor - size: 128x512\n",
       "          output : DoubleTensor - empty\n",
       "        }\n",
       "      10 : \n",
       "        nn.ReLU\n",
       "        {\n",
       "          inplace : false\n",
       "          threshold : 0\n",
       "          val : 0\n",
       "          output : DoubleTensor - empty\n",
       "          gradInput : DoubleTensor - empty\n",
       "        }\n",
       "      11 : \n",
       "        nn.Dropout(0.500000)\n",
       "        {\n",
       "          v2 : true\n",
       "          noise : DoubleTensor - empty\n",
       "          train : true\n",
       "      "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "    p : 0.5\n",
       "          gradInput : DoubleTensor - empty\n",
       "          output : DoubleTensor - empty\n",
       "        }\n",
       "      12 : \n",
       "        nn.Linear(128 -> 10)\n",
       "        {\n",
       "          gradBias : DoubleTensor - size: 10\n",
       "          weight : DoubleTensor - size: 10x128\n",
       "          bias : DoubleTensor - size: 10\n",
       "          gradInput : DoubleTensor - empty\n",
       "          gradWeight : DoubleTensor - size: 10x128\n",
       "          output : DoubleTensor - empty\n",
       "        }\n",
       "    }\n",
       "  output : DoubleTensor - empty\n",
       "}\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- network structure taken from \n",
    "-- http://nbviewer.ipython.org/github/eladhoffer/Talks/blob/master/DL_class2015/Deep%20Learning%20with%20Torch.ipynb\n",
    "net = nn.Sequential()\n",
    "net:add(nn.SpatialConvolution(1, 8, 5, 5)) -- 1 input image channel, 64 output channels, 5x5 convolution kernel\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))      -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "net:add(nn.ReLU())                          -- ReLU activation function\n",
    "net:add(nn.SpatialConvolution(8, 16, 3, 3))\n",
    "net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.SpatialConvolution(16, 32, 3, 3))\n",
    "net:add(nn.View(32*4*4):setNumInputDims(3)) -- reshapes from a 3D tensor of 32x4x4 into 1D tensor of 32*4*4\n",
    "net:add(nn.Linear(32*4*4, 128))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "net:add(nn.ReLU())\n",
    "net:add(nn.Dropout(0.5))                    --Dropout layer with p=0.5\n",
    "net:add(nn.Linear(128,10))                  -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "\n",
    "-- loss is cross-entropy (== logsoftmax + classnllcriterion)\n",
    "loss = nn.CrossEntropyCriterion():cuda()\n",
    "print(net)\n",
    "\n",
    "-- move entire network to the GPU\n",
    "net = net:cuda()\n",
    "\n",
    "parameters, gradParameters = net:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Random init complete\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- random initialization according to Xavier\n",
    "local tmp = math.sqrt(1. / 25)\n",
    "net:get(1).weight:uniform(-tmp, tmp)\n",
    "net:get(1).bias:zero()\n",
    "tmp = math.sqrt(1. / 9)\n",
    "net:get(4).weight:uniform(-tmp, tmp)\n",
    "net:get(4).bias:zero()\n",
    "tmp = math.sqrt(1. / 9)\n",
    "net:get(7).weight:uniform(-tmp, tmp)\n",
    "net:get(7).bias:zero()\n",
    "\n",
    "tmp = math.sqrt(1. / net:get(9).bias:size(1))\n",
    "net:get(9).weight:uniform(-tmp, tmp)\n",
    "net:get(9).bias:zero()\n",
    "tmp = math.sqrt(1. / net:get(12).bias:size(1))\n",
    "net:get(12).weight:uniform(-tmp, tmp)\n",
    "net:get(12).bias:zero()\n",
    "\n",
    "-- initialize state for the optimizer\n",
    "opt_state = {}\n",
    "print('Random init complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "******************* EPOCH 1 ************************\t\n",
       "TRAINING [error = 15617.553837895]\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ConfusionMatrix:\n",
       "[[    5686       7      24      13      21      31      67      16      36      22]   95.999% \t[class: 0]\n",
       " [       3    6499      64      16      18      13      15      35      67      12]   96.396% \t[class: 1]\n",
       " [      37      64    5447      84      57      11      60      77     100      21]   91.423% \t[class: 2]\n",
       " [      30      36     103    5554       9     148      21      70     106      54]   90.589% \t[class: 3]\n",
       " [      29      38      29       7    5337      14      93      28      45     222]   91.356% \t[class: 4]\n",
       " [      52      24       6     169      24    4869      89      18     122      48]   89.817% \t[class: 5]\n",
       " [      77      29      28      10      66      74    5566       8      48      12]   94.052% \t[class: 6]\n",
       " [      34      51      64      58      52      17      16    5795      32     146]   92.498% \t[class: 7]\n",
       " [      30      77      91      90      44     107      58      33    5217     104]   89.164% \t[class: 8]\n",
       " [      41      43      23      72     202      37      29     168      64    5270]]  88.586% \t[class: 9]\n",
       " + average row correct: 91.988017559052% \n",
       " + average rowUcol correct (VOC measure): 85.247970223427% \n",
       " + global correct: 92.066666666667%\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "TESTING [error = 1094.9916245341]\t\n",
       "ConfusionMatrix:\n",
       "[[     958       0       3       1       0       3       7       1       2       5]   97.755% \t[class: 0]\n",
       " [       1    1119       2       2       0       2       0       5       3       1]   98.590% \t[class: 1]\n",
       " [       4       4     990      11       0       0       2       9      12       0]   95.930% \t[class: 2]\n",
       " [       1       0       4     960       0      34       0       4       4       3]   95.050% \t[class: 3]\n",
       " [       2       1       0       0     939       1       7       2       4      26]   95.621% \t[class: 4]\n",
       " [       2       1       0       3       0     880       3       0       1       2]   98.655% \t[class: 5]\n",
       " [       6       2       0       0       1      23     922       0       4       0]   96.242% \t[class: 6]\n",
       " [       2       1       8       4       3       1       0     994       4      11]   96.693% \t[class: 7]\n",
       " [       4       1       4       2       4      11       2       4     935       7]   95.996% \t[class: 8]\n",
       " [       4       3       0       3       7       6       0       4       5     977]]  96.829% \t[class: 9]\n",
       " + average row correct: 96.736025810242% \n",
       " + average rowUcol correct (VOC measure): 93.634903430939% \n",
       " + global correct: 96.74%\t\n",
       "Epoch took 84.900701999664 seconds.\t\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- optimization parameters\n",
    "nepochs = 1\n",
    "ntrain = 60000\n",
    "--ntrain = 10000\n",
    "ntest = 10000\n",
    "batch_size = 100\n",
    "etest = 1\n",
    "\n",
    "-- SGD\n",
    "--opt_param = {\n",
    "--    learningRate = 0.01,\n",
    "--    momentum = 0.9,\n",
    "--    learningRateDecay = 1e-3\n",
    "--}\n",
    "\n",
    "-- AdaDelta\n",
    "execute_optimizer = optim.adadelta\n",
    "opt_params = {\n",
    "    rho = 0.9,\n",
    "    eps = 1e-6\n",
    "}\n",
    "\n",
    "-- train the network\n",
    "for e=1,nepochs do\n",
    "    \n",
    "    local timer = torch.Timer() \n",
    "    local confmat = optim.ConfusionMatrix(10, {'0','1','2','3','4','5','6','7','8','9'})\n",
    "    local train_err = 0\n",
    "    for b=1,ntrain/batch_size do\n",
    "        \n",
    "        function batch_eval(x)\n",
    "            \n",
    "            local err = 0\n",
    "            \n",
    "            if x ~= parameters then\n",
    "                parameters:copy(x)\n",
    "            end\n",
    "            \n",
    "            -- DO NOT FORGET TO ZERO THE GRADIENT STORAGE\n",
    "            -- BEFORE EACH MINIBATCH\n",
    "            gradParameters:zero()\n",
    "        \n",
    "            for i=1,batch_size do\n",
    "                -- select current training example\n",
    "                local ndx = (b-1) * batch_size + i\n",
    "                local x = train_data.data[ndx]\n",
    "                local t = train_data.labels[ndx]\n",
    "            \n",
    "                -- run it through the network & accumulate error\n",
    "                local y = net:forward(x)\n",
    "                err = err + loss:forward(y, t)\n",
    "                \n",
    "                confmat:add(y, t)\n",
    "\n",
    "                -- run it backward from the loss criterion\n",
    "                local dt_dy = loss:backward(y, t) \n",
    "                net:backward(x, dt_dy)\n",
    "            end\n",
    "            \n",
    "            train_err = train_err + err\n",
    "            \n",
    "            return err, gradParameters\n",
    "        end\n",
    "        \n",
    "        execute_optimizer(batch_eval, parameters, opt_params, opt_state)\n",
    "    end\n",
    "    \n",
    "    print('******************* EPOCH ' .. e .. ' ************************')\n",
    "\n",
    "    print('TRAINING [error = ' .. train_err .. ']')\n",
    "    print(confmat:__tostring__())\n",
    "    \n",
    "    -- compute testing error every etest epochs\n",
    "    if e % etest == 0 then\n",
    "        local terr = 0\n",
    "        local p = 0\n",
    "        confmat:zero()\n",
    "        for i=1,ntest do\n",
    "            local x = test_data.data[i]\n",
    "            local t = test_data.labels[i]\n",
    "            local y = net:forward(x)\n",
    "            confmat:add(y, t)\n",
    "            terr = terr + loss:forward(y, t)\n",
    "        end\n",
    "        print('TESTING [error = ' .. terr .. ']')\n",
    "        print(confmat:__tostring__())\n",
    "    end\n",
    "        \n",
    "    print('Epoch took ' .. timer:time().real .. ' seconds.')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Let us pass the image through the first convolutional layer and look at the results\n",
    "imgf = net:get(1):forward(img)\n",
    "print('Source input')\n",
    "itorch.image(img)\n",
    "print('After convolution')\n",
    "itorch.image(image.scale(image.toDisplayTensor({input=imgf}),400))\n",
    "print('Convolutional filters')\n",
    "scaled_weights = image.scale(image.toDisplayTensor({input=net:get(1).weight,padding=2}),300)\n",
    "itorch.image(scaled_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
